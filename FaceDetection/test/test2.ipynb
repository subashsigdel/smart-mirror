{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@26.892] global cap_v4l.cpp:999 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@26.895] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open video capture from a camera or video file\n",
    "cap = cv2.VideoCapture(0)  # 0 for the default camera\n",
    "\n",
    "# Screen dimensions (modify as per your screen size)\n",
    "screen_width = 1280\n",
    "screen_height = 720\n",
    "\n",
    "# Set colors for the layout\n",
    "background_color = (0, 255, 255)  # Purple-like color\n",
    "text_color = (255, 255, 255)  # White color\n",
    "\n",
    "# Set dimensions for the layout (adjust these as per your design)\n",
    "left_panel_width = int(screen_width * 0.5)  # Left panel takes half of the screen width\n",
    "right_panel_width = screen_width - left_panel_width\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow('Attendance System', cv2.WINDOW_NORMAL)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Resize the frame to fit the right panel\n",
    "    frame_resized = cv2.resize(frame, (right_panel_width, screen_height))\n",
    "\n",
    "    # Create a blank canvas for the layout\n",
    "    canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "    canvas[:] = background_color  # Set the background color for the whole canvas\n",
    "\n",
    "    # Place the camera feed on the right side of the screen\n",
    "    canvas[:, left_panel_width:] = frame_resized\n",
    "\n",
    "    # Add details to the left panel (such as text or icons)\n",
    "    cv2.putText(canvas, 'ATTENDANCE SYSTEM', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, text_color, 2, cv2.LINE_AA)\n",
    "    cv2.putText(canvas, 'ACTIVE', (150, 400), cv2.FONT_HERSHEY_SIMPLEX, 1.5, text_color, 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Add a rounded rectangle for a button (simulating the button in your image)\n",
    "    cv2.rectangle(canvas, (130, 370), (270, 430), (200, 150, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting layout\n",
    "    cv2.imshow('Attendance System', canvas)\n",
    "    \n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open video capture from a camera or video file\n",
    "cap = cv2.VideoCapture(0)  # 0 for the default camera\n",
    "\n",
    "# Screen dimensions (modify as per your screen size)\n",
    "screen_width = 1280\n",
    "screen_height = 720\n",
    "\n",
    "# Set colors for the layout\n",
    "background_color = (128, 128, 0)  # Soft blue gradient-like background color\n",
    "text_color = (255, 255, 255)  # White color for text\n",
    "border_color = (255, 255, 255)  # White border color\n",
    "\n",
    "# Set dimensions for the layout (adjust these as per your design)\n",
    "left_panel_width = int(screen_width * 0.5)  # Left panel takes half of the screen width\n",
    "right_panel_width = screen_width - left_panel_width\n",
    "\n",
    "# Load a passport-size image (replace 'testimage/राम.png' with the actual path to your image)\n",
    "passport_img = cv2.imread('/home/subash/vs/facedetection/smart-mirror/FaceDetection/test/testimage/ramp.png')\n",
    "\n",
    "# Resize the passport photo to fit within a specific area\n",
    "passport_img_resized = cv2.resize(passport_img, (150, 150))  # Adjust size as needed\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow('Attendance System', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Set the desired height of the camera feed (70% of the screen height)\n",
    "camera_feed_height = int(screen_height * 0.7)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Calculate the aspect ratio and resize the frame\n",
    "    aspect_ratio = frame.shape[1] / frame.shape[0]  # Keep aspect ratio\n",
    "    frame_resized_width = int(camera_feed_height * aspect_ratio)\n",
    "    \n",
    "    # Ensure that the resized frame width doesn't exceed the right panel's width\n",
    "    max_available_width = right_panel_width - 20  # 20 pixels padding for the border\n",
    "    if frame_resized_width > max_available_width:\n",
    "        frame_resized_width = max_available_width  # Limit the width to fit the panel\n",
    "        camera_feed_height = int(frame_resized_width / aspect_ratio)  # Adjust the height to maintain aspect ratio\n",
    "    \n",
    "    frame_resized = cv2.resize(frame, (frame_resized_width, camera_feed_height))  # Resize the frame\n",
    "\n",
    "    # Create a blank canvas for the layout\n",
    "    canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "    canvas[:] = background_color  # Set the background color for the whole canvas\n",
    "\n",
    "    # Place the camera feed on the right side of the screen with a border around it\n",
    "    x_offset = left_panel_width + 10  # X position of the camera feed\n",
    "    y_offset = (screen_height - camera_feed_height) // 2  # Center the camera feed vertically\n",
    "    canvas[y_offset:y_offset + camera_feed_height, x_offset:x_offset + frame_resized_width] = frame_resized\n",
    "\n",
    "    # Draw a border around the camera feed\n",
    "    cv2.rectangle(canvas, (x_offset - 5, y_offset - 5), (x_offset + frame_resized_width + 5, y_offset + camera_feed_height + 5), border_color, 3)\n",
    "\n",
    "    # Center the passport photo within its frame\n",
    "    photo_x_offset = (left_panel_width - 150) // 2\n",
    "    photo_y_offset = 150  # Top position for the photo\n",
    "\n",
    "    # Draw a border around the ID card section\n",
    "    id_card_height = 460  # Height of the ID card section\n",
    "    id_card_y_offset = 145  # Y position for the ID card section\n",
    "\n",
    "    # Draw a rectangle for the ID card border, matching the left panel width\n",
    "    cv2.rectangle(canvas, (2, id_card_y_offset - 30), (left_panel_width-30, id_card_y_offset + id_card_height), border_color, 3)\n",
    "\n",
    "    # Place the passport photo on the canvas\n",
    "    canvas[photo_y_offset:photo_y_offset + 150, photo_x_offset:photo_x_offset + 150] = passport_img_resized\n",
    "\n",
    "    # Add the person's name under the photo\n",
    "    cv2.putText(canvas, 'Name: Ram', (photo_x_offset, photo_y_offset + 160), cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2, cv2.LINE_AA)\n",
    "\n",
    "    # Add the total visits under the name\n",
    "    cv2.putText(canvas, 'Total Visits: 5', (photo_x_offset, photo_y_offset + 200), cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2, cv2.LINE_AA)\n",
    "\n",
    "    # Add details to the left panel (such as \"Museum Attendance System\")\n",
    "    cv2.putText(canvas, 'Museum', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, text_color, 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting layout\n",
    "    cv2.imshow('Attendance System', canvas)\n",
    "    \n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n",
      "Jane Smith\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = \"John Doe and Jane Smith attended the conference.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract names\n",
    "for entity in doc.ents:\n",
    "    if entity.label_ == \"PERSON\":\n",
    "        print(entity.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Rajan/NepaliBERT does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Load the tokenizer and model\u001B[39;00m\n\u001B[1;32m      4\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m BertTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRajan/NepaliBERT\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mBertForTokenClassification\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mRajan/NepaliBERT\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Prepare input text\u001B[39;00m\n\u001B[1;32m      8\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mराम शर्मा विद्यालय गए।\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/smartmirror/lib/python3.12/site-packages/transformers/modeling_utils.py:3708\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3702\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m   3703\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not appear to have a file named\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3704\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_add_variant(WEIGHTS_NAME,\u001B[38;5;250m \u001B[39mvariant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m but there is a file without the variant\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3705\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvariant\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Use `variant=None` to load this model from those weights.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3706\u001B[0m                 )\n\u001B[1;32m   3707\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3708\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m   3709\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not appear to have a file named\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3710\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_add_variant(WEIGHTS_NAME,\u001B[38;5;250m \u001B[39mvariant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001B[38;5;250m \u001B[39mvariant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3711\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTF2_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTF_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mFLAX_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3712\u001B[0m                 )\n\u001B[1;32m   3714\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m:\n\u001B[1;32m   3715\u001B[0m     \u001B[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted\u001B[39;00m\n\u001B[1;32m   3716\u001B[0m     \u001B[38;5;66;03m# to the original exception.\u001B[39;00m\n\u001B[1;32m   3717\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mOSError\u001B[0m: Rajan/NepaliBERT does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack."
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('Rajan/NepaliBERT')\n",
    "model = BertForTokenClassification.from_pretrained('Rajan/NepaliBERT')\n",
    "\n",
    "# Prepare input text\n",
    "text = \"राम शर्मा विद्यालय गए।\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get model predictions (inference)\n",
    "outputs = model(**inputs)\n",
    "predictions = outputs.logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartmirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
