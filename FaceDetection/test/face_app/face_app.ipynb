{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining encoding\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 149\u001b[0m\n\u001b[1;32m    147\u001b[0m recognized_face_name \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    148\u001b[0m voices \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoices\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 149\u001b[0m jsonData \u001b[38;5;241m=\u001b[39m \u001b[43mencode_photo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Create arrays of known face encodings and their names\u001b[39;00m\n\u001b[1;32m    151\u001b[0m known_face_encodings \u001b[38;5;241m=\u001b[39m [data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m jsonData]\n",
      "Cell \u001b[0;32mIn[2], line 57\u001b[0m, in \u001b[0;36mencode_photo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m nep_word,eng_word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnepali_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m),data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m eng_word\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m voices:\n\u001b[0;32m---> 57\u001b[0m             \u001b[43msave_sound\u001b[49m\u001b[43m(\u001b[49m\u001b[43meng_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnep_word\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     newData\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[2], line 106\u001b[0m, in \u001b[0;36msave_sound\u001b[0;34m(eng_word, nep_word)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_sound\u001b[39m(eng_word,nep_word):\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Synthesizes speech from the input string of text.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m texttospeech\n\u001b[1;32m    108\u001b[0m     client \u001b[38;5;241m=\u001b[39m texttospeech\u001b[38;5;241m.\u001b[39mTextToSpeechClient()\n\u001b[1;32m    109\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m texttospeech\u001b[38;5;241m.\u001b[39mSynthesisInput(text\u001b[38;5;241m=\u001b[39mnep_word)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "from playsound import playsound\n",
    "from pydub import AudioSegment\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"voice-assistant-319108-af676312c70d.json\"\n",
    "\n",
    "credentials = {\n",
    "  \"type\": \"service_account\",\n",
    "  \"project_id\": \"voice-assistant-319108\",\n",
    "  \"private_key_id\": \"af676312c70d8378f715bf78c3e0cf62a8a70666\",\n",
    "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDgnrijnsxZUdF8\\njrflz2OyFLomCJldqUUl9QgK7fZo40RlWgdcMEbknuQGHd24h6VbT+TlUYCNpi3U\\nzql0tynYFBNeAHrLxA/24U6Rq7PmKbICDpJ6wUidkY3E2oD9dH9VOcA2yZBJ6GGx\\nDh9QraS4rcRa0ZbPxzknlb+8uIsoRkK43IBZW5MJnGbLegYh0VdGrOUuu8ERuOiS\\nvDNzzCK5dIxFIEAAXvBXU2hufMlTWzMrJs7Zq6sUvW5GXY1sY0wbQFylflqeDg1V\\nHpM990esPU1UCJPBQH69TaUxeDLOIZq5z7Pdqn+5Spo++jCfa2hIYJoiBYliGsZi\\nijpM2R6xAgMBAAECggEAIM4dkkv5dVwVN9dSNV6WJWaQj0h3Oa4kmrgQLiR19fin\\nPxQoegbU+8PW8qu++5nYBR+EgxdlqopoLCnoptKvak74SyTPyl2+pSRfyLemhQl2\\n5YUCUKpU9CpTZbox15KBnE1cbMQAbkLhra2t1iceJRi/0jHFEGB80PK2d5YOQNnH\\n8FImSt8Y8mmBFtpc53gct8fqEpLUzvpiLry4eE9HmD7hbcHl6XH7fh9g/cDxQMgf\\nR4oZASrTTLhb0Hjeg9dOYQwENJA7hj0LsfVeA8rUKOPNO1fK12I/vP6y90oBTTuY\\nugGTc1HboVqqlLNUD4chWptnPPbdoJZZ0xXmpWQyVwKBgQD+HJBRC5BDRDwqibBn\\nLFh/gsYlNr7h0n7/5534o0qt5l42w8DAq45seDyGdVwiTjrF8bb+rBFuNGeuFwzI\\nzFX8wiohzbJU8bo1YAPayW5R3TXMrkghedzanEA/lKOBuZQ/6Ie/6oghlUlBLMSm\\npeEpkmTlJNkIaw6fYWCIBYqsUwKBgQDiSg0TC80bw1TGT4XhL8ctVCqHQQU/KdnY\\nlz+TmOTY6F1JYr1zqSyoMJaNUXwmig7W6DnCGkUGlKBAP+E5U3grAQc388ZnNBa0\\nLzjPgY0X/2n6cfiAUNrbxI1/jn7muf4hccawue31zG5CeWlJHpCZrmg/Jjnth1D8\\nWKSrK22IawKBgQCiZmblJNrB4q4BEZYnmfPFKjKwPdioQfrgWYpgCRwFH6E+psRd\\nXkbbk8w6sm57jjuJnf0xrY5GPD+2xwxomA6sRvreN7OtDf/PdNmBzhIvR4zGjuuS\\nWWuIWyvEdp44nf3dCiMXyC/QJrR2bsIPLxxDkUfiGjaKZsElovoqdEA3+QKBgCgQ\\nOj5cAYVf0NuHasmSnu3sj9cAcQBc1X/eT1g/YozwnsuGWspmckyYxZ7hhVyBZt0v\\nokI2SnA+0hxt8t8mYwkiFngWhdLxyu89yQ4b/rH3+3hmwztclVMBepfRz6/j0BV1\\nwlq5oGK7Pe4w9q4GZk1/Ll+30du28GStAQJ5HtxfAoGBAKjRJAB+eQ5SXmnQlZDG\\nZqloPsK/CIG2gG0gQq3IPAs0gWR/vuCt6pP78MGGb1w7JSvAnP7rBp/GwO4xWqtR\\nSIR9Hg4PZPFu6Oplgr5IFbQhGFEqnsT9ZXR31clnTEB9ypXnwT0uVCHQyXaTFqg/\\nsFfq6UWF3FdQiTuiyK57be+T\\n-----END PRIVATE KEY-----\\n\",\n",
    "  \"client_email\": \"voice-assistant@voice-assistant-319108.iam.gserviceaccount.com\",\n",
    "  \"client_id\": \"117202096327498252251\",\n",
    "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/voice-assistant%40voice-assistant-319108.iam.gserviceaccount.com\"\n",
    "}\n",
    "\n",
    "\n",
    "def encode_photo():\n",
    "    \"\"\"encodes photo and save to data.json\"\"\"\n",
    "    print('Begining encoding')\n",
    "    if os.path.getsize('data.json') != 0:\n",
    "        with open('data.json') as json_file:\n",
    "            jsonData = json.load(json_file)\n",
    "    newData = []\n",
    "    for i, cl in enumerate(myList):\n",
    "        found = False\n",
    "        for data in jsonData:\n",
    "            if cl.split('.')[0] in data['name']:\n",
    "                found = True\n",
    "\n",
    "        if not found:\n",
    "            data = {}\n",
    "            curImg = cv2.imread(f'{path}/{cl}')\n",
    "            images.append(curImg)\n",
    "            img = cv2.cvtColor(curImg, cv2.COLOR_BGR2RGB)\n",
    "            encodes = face_recognition.face_encodings(img)\n",
    "            if encodes:\n",
    "                encode = encodes[0]\n",
    "                data['name'] = cl.split('.')[0]\n",
    "                data['encoding'] = encode.tolist()\n",
    "                data['i'] = i\n",
    "                nepali_name = input(f'Enter nepali name for {data[\"name\"]}====> ')\n",
    "                data['nepali_name'] = nepali_name\n",
    "                for nep_word,eng_word in zip(data['nepali_name'].split(' '),data['name'].split(' ')):\n",
    "                    if not eng_word+'.mp3' in voices:\n",
    "                        save_sound(eng_word,nep_word)\n",
    "                newData.append(data)\n",
    "            else:\n",
    "                print(f\"Couldnot find face in {path}/{cl}\")\n",
    "    jsonData = jsonData+newData\n",
    "    with open('data.json', 'w') as outfile:\n",
    "        json.dump(jsonData, outfile)\n",
    "    print('Encoding has been completed')\n",
    "    return jsonData\n",
    "\n",
    "def recognize_face(known_face_encodings,known_face_names,jsonData):\n",
    "    print('Begining face recognition')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        for data in recognized_face_name:\n",
    "            if (datetime.now()-data['time']).seconds>60:\n",
    "                recognized_face_name.remove(data)\n",
    "        \n",
    "        # Grab a single frame of video\n",
    "        ret, frame = cap.read()\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "        # Find all the faces and face enqcodings in the frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "        print(face_locations)\n",
    "        # Loop through each face in this frame of video\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(\n",
    "                known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            # the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(\n",
    "                known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "                if not search_dictionaries('i',best_match_index,recognized_face_name):\n",
    "                    recognized_face_name.append({'i':best_match_index,'name':name,'time':datetime.now()})\n",
    "                    nepali_name = search_dictionaries('i',best_match_index,jsonData)['nepali_name']\n",
    "                    print(f'{name} has been recognized')\n",
    "                    if not f'{name.split(\" \")[0]}.mp3' in voices:\n",
    "                        save_sound(name.split(\" \")[0],f'नमस्ते {nepali_name.split(\" \")[0]} जी')\n",
    "                    playsound(f'voices/{name.split(\" \")[0]}.mp3')\n",
    "                    playsound('C:/Users/HTP/Desktop/face_app/voices/welcome_museum.mp3')\n",
    "                    time.sleep(1)\n",
    "\n",
    "def save_sound(eng_word,nep_word):\n",
    "    \"\"\"Synthesizes speech from the input string of text.\"\"\"\n",
    "    from google.cloud import texttospeech\n",
    "\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "    input_text = texttospeech.SynthesisInput(text=nep_word)\n",
    "\n",
    "    # Note: the voice can also be specified by name.\n",
    "    # Names of voices can be retrieved with client.list_voices().\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"hi-IN\",\n",
    "        name=\"hi-IN-Wavenet-D\",\n",
    "        # ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,\n",
    "    )\n",
    "\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "    \n",
    "    response = client.synthesize_speech(\n",
    "        request={\"input\": input_text, \"voice\": voice,\n",
    "                 \"audio_config\": audio_config}\n",
    "    )\n",
    "\n",
    "    # The response's audio_content is binary.\n",
    "    with open(f\"voices/{eng_word}.mp3\", \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "        out.close()\n",
    "    # playsound(f'voices/{text}.mp3')\n",
    "            \n",
    "\n",
    "def search_dictionaries(key, value, list_of_dictionaries):\n",
    "    for data in list_of_dictionaries:\n",
    "        if data[key] == value:\n",
    "            return data\n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = 'image'\n",
    "    images = []\n",
    "    classNames = []\n",
    "    myList = os.listdir(path)\n",
    "    encodeList = []\n",
    "    recognized_face_name = []\n",
    "    voices = os.listdir('voices')\n",
    "    jsonData = encode_photo()\n",
    "    # Create arrays of known face encodings and their names\n",
    "    known_face_encodings = [data['encoding'] for data in jsonData]\n",
    "    known_face_names = [data['name'] for data in jsonData]\n",
    "    recognize_face(known_face_encodings,known_face_names,jsonData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartmirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
