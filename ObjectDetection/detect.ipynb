{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install torch torchvision\n",
    "# git clone https://github.com/ultralytics/yolov5\n",
    "# cd yolov5\n",
    "# pip3 install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 detect.py --weights yolov5n.pt --source 0  # Run on a USB or Pi camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from numpy import random\n",
    "\n",
    "# Load the YOLOv5n model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5n.pt')\n",
    "\n",
    "# Define the list of specific class IDs you want to detect\n",
    "# Replace with your actual target class IDs from the COCO dataset (e.g., 0 for 'person', 2 for 'car', etc.)\n",
    "target_classes = [0, 1, 2, 3, 5, 7, 9, 10, 12, 15, 16, 20, 23, 25, 27, 30, 32, 35, 38, 40]  # Example IDs\n",
    "\n",
    "# Function to filter detection results by target class IDs\n",
    "def filter_classes(detections, target_classes):\n",
    "    filtered_results = []\n",
    "    for det in detections:\n",
    "        if int(det[5]) in target_classes:  # det[5] contains the class ID\n",
    "            filtered_results.append(det)\n",
    "    return filtered_results\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for the default camera, or a path to a video file\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform inference on the frame\n",
    "    results = model(frame)\n",
    "\n",
    "    # Extract detection results\n",
    "    detections = results.xyxy[0].numpy()\n",
    "\n",
    "    # Filter based on specific class IDs\n",
    "    filtered_detections = filter_classes(detections, target_classes)\n",
    "\n",
    "    # Draw filtered detections on the frame\n",
    "    for det in filtered_detections:\n",
    "        x1, y1, x2, y2, conf, cls = det\n",
    "        label = f\"{model.names[int(cls)]} {conf:.2f}\"\n",
    "        color = [random.randint(0, 255) for _ in range(3)]\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)\n",
    "        cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Show the result in real-time\n",
    "    cv2.imshow('Filtered Detections', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
