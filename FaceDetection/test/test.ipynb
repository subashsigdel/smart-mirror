{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing OpenCV library \n",
    "import cv2\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "import uuid  # To generate unique IDs\n",
    "\n",
    "\n",
    "def newperson(frame):\n",
    "    \n",
    "    def ask_name():\n",
    "        # Create a text-to-speech object\n",
    "        tts = gTTS(text=f\"तपाईको नाम के हो ?\", lang='ne',tld='co.in',slow=False)\n",
    "        # Save the audio file\n",
    "        audio_file = \"output.mp3\"\n",
    "        tts.save(audio_file)\n",
    "        # Play the audio file\n",
    "        playsound(audio_file)\n",
    "        # Remove the audio file after playing\n",
    "        os.remove(audio_file)\n",
    "\n",
    "    ask_name()\n",
    "\n",
    "\n",
    "    def name_input(max_retries=2, timeout=30):\n",
    "        \n",
    "        # Initialize recognizer\n",
    "        recognizer = sr.Recognizer()\n",
    "\n",
    "        for attempt in range(max_retries + 1):\n",
    "            # Capture audio from the microphone\n",
    "            with sr.Microphone() as source:\n",
    "                print(f\"Attempt {attempt + 1}: Listening in Nepali...\")\n",
    "\n",
    "                try:\n",
    "                    # Adjust for ambient noise and listen with a timeout\n",
    "                    recognizer.adjust_for_ambient_noise(source)\n",
    "                    audio = recognizer.listen(source, timeout=timeout)\n",
    "\n",
    "                    # Recognize the speech in Nepali using Google Web Speech API\n",
    "                    name = recognizer.recognize_google(audio, language=\"ne-NP\")\n",
    "                     # Process the text to remove unnecessary words\n",
    "                    # Remove \"मेरो नाम\" or \"नाम\" and extract the first name\n",
    "                    if \"मेरो नाम\" in name:\n",
    "                        name = name.replace(\"मेरो नाम\", \"\").strip()\n",
    "                    elif \"नाम\" in name:\n",
    "                        name = name.replace(\"नाम\", \"\").strip()\n",
    "                    elif \"हो\" or \"हो।\" in name:\n",
    "                        name = name.replace(\"हो\", \"\").strip()\n",
    "\n",
    "                    elif \"हो।\" in name:\n",
    "                        name = name.replace(\"हो।\", \"\").strip()\n",
    "                        \n",
    "                    print(f\"Recognized Name: {name}\")\n",
    "                    return name  # If successful, return the recognized name\n",
    "\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"Could not understand the audio, please say it again.\")\n",
    "\n",
    "                except sr.WaitTimeoutError:\n",
    "                    print(\"Listening timed out, please try saying your name again.\")\n",
    "\n",
    "                except sr.RequestError:\n",
    "                    print(\"Request failed; check your internet connection.\")\n",
    "                    break  # If there's a connection issue, break out of the loop\n",
    "\n",
    "        # If no valid name is recognized after all attempts\n",
    "        print(\"Failed to recognize after several attempts.\")\n",
    "        return name\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # initialize the camera \n",
    "    # If you have multiple camera connected with \n",
    "    # current device, assign a value in cam_port \n",
    "    # variable according to that \n",
    "    # cam_port = 0\n",
    "    # cam = cv2.VideoCapture(cam_port)\n",
    "\n",
    "    # while True:\n",
    "    #     success, img = cam.read()\n",
    "    #     #img = captureScreen()\n",
    "    #     # saving image in local storage\n",
    "    unique_id = str(uuid.uuid4().hex[:4])\n",
    "    cv2.imwrite(f\"testimage/{name_input()}-{unique_id}.png\", frame)\n",
    "        # # break\n",
    "        # #cv2.imshow('Webcam',img)\n",
    "        # #cv2.waitKey(1)\n",
    "        # cv2.imshow('my video', img)\n",
    "        # if cv2.waitKey(13) & 0xFF == ord('q'):\n",
    "        #     cv2.destroyAllWindows()\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "शुभाष-fd09\n",
      "sir\n",
      "Skipping sir, already encoded.\n",
      "No new face encodings to add.\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def append_face_encodings_to_csv(image_folder, csv_filename):\n",
    "    # List to store encodings and names for new images\n",
    "    face_data = []\n",
    "\n",
    "    # Get the names of already encoded people from the CSV\n",
    "    existing_names = set()\n",
    "    if os.path.exists(csv_filename):\n",
    "        with open(csv_filename, mode=\"r\") as file:\n",
    "            reader = csv.reader(file)\n",
    "            try:\n",
    "                # Try to skip the header row\n",
    "                next(reader)\n",
    "            except StopIteration:\n",
    "                # If the file is empty, do nothing\n",
    "                print(f\"{csv_filename} is empty, starting fresh.\")\n",
    "            else:\n",
    "                # Read all existing names\n",
    "                for row in reader:\n",
    "                    existing_names.add(row[0])  # The name is the first column\n",
    "\n",
    "    # Loop through each image in the folder\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith(\".jpeg\") or filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Get the person's name from the file name (without extension)\n",
    "            person_name = os.path.splitext(filename)[0]\n",
    "            print(person_name)\n",
    "\n",
    "            # Skip if the name already exists in the CSV\n",
    "            if person_name in existing_names:\n",
    "                print(f\"Skipping {person_name}, already encoded.\")\n",
    "                continue\n",
    "\n",
    "            # Load the image file\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "\n",
    "            # Get face encodings\n",
    "            face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "            # Check if a face was found\n",
    "            if len(face_encodings) > 0:\n",
    "                # Use the first face encoding\n",
    "                face_encoding = face_encodings[0]\n",
    "\n",
    "                # Append the name and encoding to the list\n",
    "                face_data.append([person_name] + face_encoding.tolist())\n",
    "                print(f\"Encoded and added {person_name}\")\n",
    "\n",
    "    # Append the new face data to the existing CSV file\n",
    "    with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write the header row if the file is empty\n",
    "        if os.stat(csv_filename).st_size == 0:\n",
    "            writer.writerow([\"Name\"] + [f\"Encoding_{i+1}\" for i in range(128)])  # Header\n",
    "        # Write each new person's name and encodings\n",
    "        writer.writerows(face_data)\n",
    "\n",
    "    if face_data:\n",
    "        print(f\"New face encodings appended to {csv_filename}\")\n",
    "    else:\n",
    "        print(\"No new face encodings to add.\")\n",
    "\n",
    "# Example usage:\n",
    "image_folder = \"testimage\"\n",
    "csv_filename = \"facedetails.csv\"\n",
    "append_face_encodings_to_csv(image_folder, csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known face names: ['sir']\n",
      "Number of known face encodings: [array([-1.04551472e-01,  8.17659944e-02,  6.38923645e-02,  1.58169270e-02,\n",
      "       -6.94672614e-02, -1.07918873e-01, -2.08490901e-02, -2.27949217e-01,\n",
      "        7.83200860e-02, -5.57523817e-02,  2.25337535e-01, -2.37202775e-02,\n",
      "       -2.60618895e-01, -1.16440177e-01,  9.29656345e-03,  1.93225756e-01,\n",
      "       -2.00881362e-01, -1.81660995e-01, -1.00697219e-01, -6.61356375e-02,\n",
      "       -3.66029888e-02, -5.21896034e-03,  1.24986254e-01,  4.65265512e-02,\n",
      "       -7.31325001e-02, -3.08529764e-01, -6.68666214e-02, -9.03701633e-02,\n",
      "        1.71684865e-02, -1.23930480e-02, -5.04123159e-02,  4.28354442e-02,\n",
      "       -2.76541799e-01, -1.07292652e-01,  6.30084425e-02,  1.36473298e-01,\n",
      "       -2.45851148e-02, -3.82841453e-02,  2.19216093e-01,  3.94016877e-03,\n",
      "       -1.67061716e-01, -1.07952878e-02,  8.66704956e-02,  2.07236737e-01,\n",
      "        2.50734419e-01,  1.20222718e-02,  4.25492302e-02, -1.26341134e-01,\n",
      "        8.73768181e-02, -1.64872468e-01,  2.34796368e-02,  1.13322780e-01,\n",
      "        1.01076461e-01,  5.12003340e-02, -2.56567486e-02, -1.54809445e-01,\n",
      "        1.32363662e-02,  1.60546973e-01, -1.83092028e-01, -9.36124474e-04,\n",
      "        8.62888470e-02, -1.29687399e-01, -3.08538545e-02,  1.64850764e-02,\n",
      "        2.36615747e-01,  7.12264478e-02, -8.18581507e-02, -1.75362125e-01,\n",
      "        1.39531046e-01, -1.34186149e-01, -7.99937919e-02,  7.88857043e-02,\n",
      "       -1.29921600e-01, -1.07905746e-01, -3.49774301e-01, -3.43855172e-02,\n",
      "        4.35766846e-01, -1.25463055e-02, -1.37858361e-01,  2.28616111e-02,\n",
      "       -1.12182923e-01, -7.11516812e-02,  3.85563746e-02,  8.95544887e-02,\n",
      "       -6.74271211e-03, -1.71225965e-02, -1.57558277e-01,  3.72337438e-02,\n",
      "        2.07755372e-01, -4.07689214e-02, -2.32465044e-02,  1.46399140e-01,\n",
      "       -2.85663940e-02,  4.17503342e-02,  4.16642427e-02,  8.68296027e-02,\n",
      "       -1.10409752e-01,  3.50724906e-02, -1.60412192e-01, -8.77722874e-02,\n",
      "       -4.87539247e-02, -9.79804248e-03,  2.25169994e-02,  7.23145232e-02,\n",
      "       -1.33757591e-01,  6.03486076e-02, -4.27590217e-03, -1.57158375e-02,\n",
      "       -3.27944495e-02, -7.43352175e-02, -4.31258790e-02, -6.80633932e-02,\n",
      "        9.47656408e-02, -2.54786193e-01,  2.18899772e-01,  1.95884019e-01,\n",
      "       -2.83903852e-02,  1.04769044e-01,  2.36121640e-02,  6.52276576e-02,\n",
      "       -3.59484032e-02, -1.77413225e-04, -1.77990317e-01, -4.46863621e-02,\n",
      "        4.87238318e-02,  2.06438676e-02,  1.25560313e-01,  4.17182893e-02])]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def load_face_encodings_from_csv(csv_filename):\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    if os.path.exists(csv_filename):\n",
    "        with open(csv_filename, mode=\"r\") as file:\n",
    "            reader = csv.reader(file)\n",
    "            header = next(reader)  # Skip the header row\n",
    "\n",
    "            for row in reader:\n",
    "                name = row[0]\n",
    "                encoding = list(map(float, row[1:]))  # Convert all encoding values to float\n",
    "\n",
    "                known_face_names.append(name)\n",
    "                known_face_encodings.append(np.array(encoding))\n",
    "\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "# Example usage\n",
    "csv_filename = \"facedetails.csv\"\n",
    "known_face_encodings, known_face_names = load_face_encodings_from_csv(csv_filename)\n",
    "\n",
    "print(\"Known face names:\", known_face_names)\n",
    "print(\"Number of known face encodings:\", known_face_encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import face_recognition\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from gtts import gTTS\n",
    "# from playsound import playsound\n",
    "# import os\n",
    "# import time\n",
    "# # Get a reference to webcam #0 (the default one)\n",
    "# video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# def greet_person(name):\n",
    "#     # Create a text-to-speech object\n",
    "#     tts = gTTS(text=f\"{name} नमस्ते!\", lang='ne', tld='co.in', slow=False)\n",
    "#     # Save the audio file\n",
    "#     audio_file = \"output.mp3\"\n",
    "#     tts.save(audio_file)\n",
    "#     # Play the audio file\n",
    "#     playsound(audio_file)\n",
    "#     # Remove the audio file after playing\n",
    "#     os.remove(audio_file)\n",
    "\n",
    "# # Initialize variables\n",
    "# face_locations = []\n",
    "# face_encodings = []\n",
    "# face_names = []\n",
    "# process_this_frame = True\n",
    "# greeted_names = set()  # Set to keep track of greeted names\n",
    "\n",
    "# # Static bounding box for face alignment (in the middle of the screen)\n",
    "# static_box_start = (150, 100)  # top-left corner of the static bounding box\n",
    "# static_box_end = (450, 400)    # bottom-right corner of the static bounding box\n",
    "\n",
    "# # Initialize a timer\n",
    "# last_reset_time = time.time()  # Get the current time\n",
    "# reset_interval = 3600  # Set the reset interval to 1 hour (3600 seconds)\n",
    "\n",
    "# while True:\n",
    "\n",
    "#     # Grab a single frame of video\n",
    "#     ret, frame = video_capture.read()\n",
    "\n",
    "#     # Draw the static bounding box on the frame\n",
    "#     cv2.rectangle(frame, static_box_start, static_box_end, (0, 255, 0), 2)\n",
    "\n",
    "#     # Only process every other frame of video to save time\n",
    "#     if process_this_frame:\n",
    "#         # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "#         small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "#         # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "#         rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         # Find all the faces and face encodings in the current frame of video\n",
    "#         face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "#         face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "#         face_names = []\n",
    "#         for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "#             # Scale up the face location\n",
    "#             top, right, bottom, left = [v * 4 for v in face_location]\n",
    "\n",
    "#             # See if the face is a match for the known face(s)\n",
    "#             matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "#             name = \"Unknown\"\n",
    "\n",
    "#             # Use the known face with the smallest distance to the new face\n",
    "#             face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "#             best_match_index = np.argmin(face_distances)\n",
    "#             if matches[best_match_index]:\n",
    "#                 name = known_face_names[best_match_index]\n",
    "\n",
    "#             face_names.append(name)\n",
    "\n",
    "#             # Check if the face is inside the static bounding box\n",
    "#             if (left > static_box_start[0] and right < static_box_end[0] and \n",
    "#                 top > static_box_start[1] and bottom < static_box_end[1]):\n",
    "                \n",
    "#                 if name == \"Unknown\":\n",
    "#                     # Capture the image and save it for a new person\n",
    "#                     newperson(frame)  # Custom function to handle new person\n",
    "#                     append_face_encodings_to_csv(image_folder='testimage', csv_filename='facedetails.csv')\n",
    "#                     known_face_encodings, known_face_names = load_face_encodings_from_csv('facedetails.csv')\n",
    "\n",
    "#                 # Greet the detected person if not already greeted\n",
    "#                 if name != \"Unknown\" and name not in greeted_names:\n",
    "#                     greet_person(name)\n",
    "#                     greeted_names.add(name)  # Add name to the set of greeted names\n",
    "\n",
    "#     process_this_frame = not process_this_frame\n",
    "\n",
    "#     # Display the results\n",
    "#     for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "#         # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "#         top *= 4\n",
    "#         right *= 4\n",
    "#         bottom *= 4\n",
    "#         left *= 4\n",
    "\n",
    "#         # Draw a box around the face\n",
    "#         cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "#         # Optionally, draw the person's name on the screen\n",
    "#         cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "#         font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#         cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "#     # Display the resulting image\n",
    "#     cv2.imshow('Video', frame)\n",
    "\n",
    "#     # Hit 'q' on the keyboard to quit\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release handle to the webcam\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "import time\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "def greet_person(name):\n",
    "    base_name = name.split('-')[0]\n",
    "    # Create a text-to-speech object\n",
    "    tts = gTTS(text=f\"{base_name} नमस्ते!\", lang='ne', tld='co.in', slow=False)\n",
    "    # Save the audio file\n",
    "    audio_file = \"output.mp3\"\n",
    "    tts.save(audio_file)\n",
    "    # Play the audio file\n",
    "    playsound(audio_file)\n",
    "    # Remove the audio file after playing\n",
    "    os.remove(audio_file)\n",
    "\n",
    "# Initialize variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "greeted_names = set()  # Set to keep track of greeted names\n",
    "\n",
    "# Static bounding box for face alignment (in the middle of the screen)\n",
    "static_box_start = (150, 100)  # top-left corner of the static bounding box\n",
    "static_box_end = (450, 400)    # bottom-right corner of the static bounding box\n",
    "\n",
    "# Initialize a timer\n",
    "last_reset_time = time.time()  # Get the current time\n",
    "reset_interval = 3600  # Set the reset interval to 1 hour (3600 seconds)\n",
    "\n",
    "while True:\n",
    "     # Clear the greeted names every hour\n",
    "    current_time = time.time()\n",
    "    if current_time - last_reset_time >= reset_interval:\n",
    "        greeted_names.clear()  # Clear the greeted names\n",
    "        last_reset_time = current_time  # Reset the timer\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Draw the static bounding box on the frame\n",
    "    cv2.rectangle(frame, static_box_start, static_box_end, (0, 255, 0), 2)\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            # Scale up the face location\n",
    "            top, right, bottom, left = [v * 4 for v in face_location]\n",
    "\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "            # Check if the face is inside the static bounding box\n",
    "            if (left > static_box_start[0] and right < static_box_end[0] and \n",
    "                top > static_box_start[1] and bottom < static_box_end[1]):\n",
    "                \n",
    "                if name == \"Unknown\":\n",
    "                    # Capture the image and save it for a new person\n",
    "                    newperson(frame)  # Custom function to handle new person\n",
    "                    append_face_encodings_to_csv(image_folder='testimage', csv_filename='facedetails.csv')\n",
    "                    known_face_encodings, known_face_names = load_face_encodings_from_csv('facedetails.csv')\n",
    "\n",
    "                # Greet the detected person if not already greeted\n",
    "                if name != \"Unknown\" and name not in greeted_names:\n",
    "                    greet_person(name)\n",
    "                    greeted_names.add(name)  # Add name to the set of greeted names\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Optionally, draw the person's name on the screen\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartmirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
