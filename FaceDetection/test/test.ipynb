{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing OpenCV library \n",
    "import cv2\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "def newperson(frame):\n",
    "    \n",
    "    def ask_name():\n",
    "        # Create a text-to-speech object\n",
    "        tts = gTTS(text=f\"Tapaiko Naam Ke ho ?\", lang='ne',tld='co.in',slow=False)\n",
    "        # Save the audio file\n",
    "        audio_file = \"output.mp3\"\n",
    "        tts.save(audio_file)\n",
    "        # Play the audio file\n",
    "        playsound(audio_file)\n",
    "        # Remove the audio file after playing\n",
    "        os.remove(audio_file)\n",
    "\n",
    "    ask_name()\n",
    "\n",
    "    def name_input():\n",
    "        # Initialize recognizer\n",
    "        recognizer = sr.Recognizer()\n",
    "\n",
    "        # Capture audio from the microphone\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Listening in Nepali...\")\n",
    "            audio = recognizer.listen(source)\n",
    "\n",
    "            try:\n",
    "                # Recognize the speech in Nepali using Google Web Speech API\n",
    "                name = recognizer.recognize_google(audio, language=\"ne-NP\")\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand the audio\")\n",
    "            except sr.RequestError:\n",
    "                print(\"Request failed; check your internet connection\")\n",
    "        return name\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # initialize the camera \n",
    "    # If you have multiple camera connected with \n",
    "    # current device, assign a value in cam_port \n",
    "    # variable according to that \n",
    "    # cam_port = 0\n",
    "    # cam = cv2.VideoCapture(cam_port)\n",
    "\n",
    "    # while True:\n",
    "    #     success, img = cam.read()\n",
    "    #     #img = captureScreen()\n",
    "    #     # saving image in local storage \n",
    "    \n",
    "    cv2.imwrite(f\"testimage/{name_input()}.png\", frame)\n",
    "        # # break\n",
    "        # #cv2.imshow('Webcam',img)\n",
    "        # #cv2.waitKey(1)\n",
    "        # cv2.imshow('my video', img)\n",
    "        # if cv2.waitKey(13) & 0xFF == ord('q'):\n",
    "        #     cv2.destroyAllWindows()\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping sir, already encoded.\n",
      "No new face encodings to add.\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def append_face_encodings_to_csv(image_folder, csv_filename):\n",
    "    # List to store encodings and names for new images\n",
    "    face_data = []\n",
    "\n",
    "    # Get the names of already encoded people from the CSV\n",
    "    existing_names = set()\n",
    "    if os.path.exists(csv_filename):\n",
    "        with open(csv_filename, mode=\"r\") as file:\n",
    "            reader = csv.reader(file)\n",
    "            try:\n",
    "                # Try to skip the header row\n",
    "                next(reader)\n",
    "            except StopIteration:\n",
    "                # If the file is empty, do nothing\n",
    "                print(f\"{csv_filename} is empty, starting fresh.\")\n",
    "            else:\n",
    "                # Read all existing names\n",
    "                for row in reader:\n",
    "                    existing_names.add(row[0])  # The name is the first column\n",
    "\n",
    "    # Loop through each image in the folder\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith(\".jpeg\") or filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Get the person's name from the file name (without extension)\n",
    "            person_name = os.path.splitext(filename)[0]\n",
    "\n",
    "            # Skip if the name already exists in the CSV\n",
    "            if person_name in existing_names:\n",
    "                print(f\"Skipping {person_name}, already encoded.\")\n",
    "                continue\n",
    "\n",
    "            # Load the image file\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "\n",
    "            # Get face encodings\n",
    "            face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "            # Check if a face was found\n",
    "            if len(face_encodings) > 0:\n",
    "                # Use the first face encoding\n",
    "                face_encoding = face_encodings[0]\n",
    "\n",
    "                # Append the name and encoding to the list\n",
    "                face_data.append([person_name] + face_encoding.tolist())\n",
    "                print(f\"Encoded and added {person_name}\")\n",
    "\n",
    "    # Append the new face data to the existing CSV file\n",
    "    with open(csv_filename, mode=\"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write the header row if the file is empty\n",
    "        if os.stat(csv_filename).st_size == 0:\n",
    "            writer.writerow([\"Name\"] + [f\"Encoding_{i+1}\" for i in range(128)])  # Header\n",
    "        # Write each new person's name and encodings\n",
    "        writer.writerows(face_data)\n",
    "\n",
    "    if face_data:\n",
    "        print(f\"New face encodings appended to {csv_filename}\")\n",
    "    else:\n",
    "        print(\"No new face encodings to add.\")\n",
    "\n",
    "# Example usage:\n",
    "image_folder = \"testimage\"\n",
    "csv_filename = \"facedetails.csv\"\n",
    "append_face_encodings_to_csv(image_folder, csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known face names: ['sir']\n",
      "Number of known face encodings: [array([-1.04551524e-01,  8.17660615e-02,  6.38923347e-02,  1.58169027e-02,\n",
      "       -6.94673732e-02, -1.07918844e-01, -2.08491236e-02, -2.27949291e-01,\n",
      "        7.83200413e-02, -5.57524785e-02,  2.25337625e-01, -2.37203259e-02,\n",
      "       -2.60618776e-01, -1.16440207e-01,  9.29652154e-03,  1.93225726e-01,\n",
      "       -2.00881451e-01, -1.81661054e-01, -1.00697257e-01, -6.61355704e-02,\n",
      "       -3.66029069e-02, -5.21890493e-03,  1.24986209e-01,  4.65265587e-02,\n",
      "       -7.31325746e-02, -3.08529794e-01, -6.68665767e-02, -9.03701037e-02,\n",
      "        1.71684884e-02, -1.23930285e-02, -5.04123494e-02,  4.28354740e-02,\n",
      "       -2.76541919e-01, -1.07292563e-01,  6.30083531e-02,  1.36473238e-01,\n",
      "       -2.45850850e-02, -3.82841490e-02,  2.19216079e-01,  3.94019485e-03,\n",
      "       -1.67061761e-01, -1.07953837e-02,  8.66704285e-02,  2.07236692e-01,\n",
      "        2.50734478e-01,  1.20223407e-02,  4.25493009e-02, -1.26341000e-01,\n",
      "        8.73768479e-02, -1.64872423e-01,  2.34796256e-02,  1.13322787e-01,\n",
      "        1.01076372e-01,  5.12003489e-02, -2.56567672e-02, -1.54809415e-01,\n",
      "        1.32363504e-02,  1.60546973e-01, -1.83091909e-01, -9.36131692e-04,\n",
      "        8.62888023e-02, -1.29687309e-01, -3.08538228e-02,  1.64850540e-02,\n",
      "        2.36615717e-01,  7.12264106e-02, -8.18581283e-02, -1.75362080e-01,\n",
      "        1.39530972e-01, -1.34186104e-01, -7.99938515e-02,  7.88856745e-02,\n",
      "       -1.29921660e-01, -1.07905813e-01, -3.49774331e-01, -3.43854576e-02,\n",
      "        4.35766935e-01, -1.25463298e-02, -1.37858331e-01,  2.28615347e-02,\n",
      "       -1.12182856e-01, -7.11517930e-02,  3.85564603e-02,  8.95544440e-02,\n",
      "       -6.74270280e-03, -1.71226077e-02, -1.57558352e-01,  3.72337289e-02,\n",
      "        2.07755312e-01, -4.07689437e-02, -2.32464988e-02,  1.46399185e-01,\n",
      "       -2.85664424e-02,  4.17503603e-02,  4.16641496e-02,  8.68296996e-02,\n",
      "       -1.10409781e-01,  3.50725502e-02, -1.60412133e-01, -8.77722949e-02,\n",
      "       -4.87539768e-02, -9.79804620e-03,  2.25169212e-02,  7.23144263e-02,\n",
      "       -1.33757442e-01,  6.03486225e-02, -4.27592266e-03, -1.57158040e-02,\n",
      "       -3.27944383e-02, -7.43352771e-02, -4.31258827e-02, -6.80634007e-02,\n",
      "        9.47656557e-02, -2.54786074e-01,  2.18899772e-01,  1.95884019e-01,\n",
      "       -2.83903833e-02,  1.04769066e-01,  2.36121751e-02,  6.52276725e-02,\n",
      "       -3.59484367e-02, -1.77414156e-04, -1.77990437e-01, -4.46863659e-02,\n",
      "        4.87238653e-02,  2.06438955e-02,  1.25560343e-01,  4.17182557e-02])]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def load_face_encodings_from_csv(csv_filename):\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    if os.path.exists(csv_filename):\n",
    "        with open(csv_filename, mode=\"r\") as file:\n",
    "            reader = csv.reader(file)\n",
    "            header = next(reader)  # Skip the header row\n",
    "\n",
    "            for row in reader:\n",
    "                name = row[0]\n",
    "                encoding = list(map(float, row[1:]))  # Convert all encoding values to float\n",
    "\n",
    "                known_face_names.append(name)\n",
    "                known_face_encodings.append(np.array(encoding))\n",
    "\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "# Example usage\n",
    "csv_filename = \"facedetails.csv\"\n",
    "known_face_encodings, known_face_names = load_face_encodings_from_csv(csv_filename)\n",
    "\n",
    "print(\"Known face names:\", known_face_names)\n",
    "print(\"Number of known face encodings:\", known_face_encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import face_recognition\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from gtts import gTTS\n",
    "# from playsound import playsound\n",
    "# import os\n",
    "# # Get a reference to webcam #0 (the default one)\n",
    "# video_capture = cv2.VideoCapture(0)\n",
    "# def greet_person(name):\n",
    "#     # Create a text-to-speech object\n",
    "#     tts = gTTS(text=f\"{name} नमस्ते,!\", lang='ne',tld='co.in',slow=False)\n",
    "#     # Save the audio file\n",
    "#     audio_file = \"output.mp3\"\n",
    "#     tts.save(audio_file)\n",
    "#     # Play the audio file\n",
    "#     playsound(audio_file)\n",
    "#     # Remove the audio file after playing\n",
    "#     os.remove(audio_file)\n",
    "# # Initialize variables\n",
    "# face_locations = []\n",
    "# face_encodings = []\n",
    "# face_names = []\n",
    "# process_this_frame = True\n",
    "# greeted_names = set()  # Set to keep track of greeted names\n",
    "\n",
    "# while True:\n",
    "#     # Grab a single frame of video\n",
    "#     ret, frame = video_capture.read()\n",
    "\n",
    "#     # Only process every other frame of video to save time\n",
    "#     if process_this_frame:\n",
    "#         # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "#         small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "#         # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "#         rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "#         # Find all the faces and face encodings in the current frame of video\n",
    "#         face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "#         face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "#         face_names = []\n",
    "#         for face_encoding in face_encodings:\n",
    "#             # See if the face is a match for the known face(s)\n",
    "#             matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "#             name = \"Unknown\"\n",
    "\n",
    "#             # Or instead, use the known face with the smallest distance to the new face\n",
    "#             face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "#             best_match_index = np.argmin(face_distances)\n",
    "#             if matches[best_match_index]:\n",
    "#                 name = known_face_names[best_match_index]\n",
    "\n",
    "#             face_names.append(name)\n",
    "#             if name == \"Unknown\":\n",
    "#                 newperson(frame)\n",
    "#                 append_face_encodings_to_csv(image_folder='testimage',csv_filename='facedetails.csv')\n",
    "#                 known_face_encodings, known_face_names = load_face_encodings_from_csv('facedetails.csv')\n",
    "\n",
    "#             # Greet the detected person if not already greeted\n",
    "#             if name != \"Unknown\" and name not in greeted_names:\n",
    "#                 greet_person(name)\n",
    "#                 greeted_names.add(name)  # Add name to the set of greeted names\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "#     process_this_frame = not process_this_frame\n",
    "\n",
    "#     # Display the results\n",
    "#     for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "#         # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "#         top *= 4\n",
    "#         right *= 4\n",
    "#         bottom *= 4\n",
    "#         left *= 4\n",
    "\n",
    "#         # Draw a box around the face\n",
    "#         cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "#         # # Draw a label with a name below the face\n",
    "#         # cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "#         # font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#         # cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "#     # Display the resulting image\n",
    "#     cv2.imshow('Video', frame)\n",
    "\n",
    "#     # Hit 'q' on the keyboard to quit!\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release handle to the webcam\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening in Nepali...\n",
      "Encoded and added शुभाष\n",
      "Skipping sir, already encoded.\n",
      "New face encodings appended to facedetails.csv\n",
      "Listening in Nepali...\n",
      "Encoded and added ram\n",
      "Skipping शुभाष, already encoded.\n",
      "Skipping sir, already encoded.\n",
      "New face encodings appended to facedetails.csv\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "def greet_person(name):\n",
    "    # Create a text-to-speech object\n",
    "    tts = gTTS(text=f\"{name} नमस्ते!\", lang='ne', tld='co.in', slow=False)\n",
    "    # Save the audio file\n",
    "    audio_file = \"output.mp3\"\n",
    "    tts.save(audio_file)\n",
    "    # Play the audio file\n",
    "    playsound(audio_file)\n",
    "    # Remove the audio file after playing\n",
    "    os.remove(audio_file)\n",
    "\n",
    "# Initialize variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "greeted_names = set()  # Set to keep track of greeted names\n",
    "\n",
    "# Static bounding box for face alignment (in the middle of the screen)\n",
    "static_box_start = (150, 100)  # top-left corner of the static bounding box\n",
    "static_box_end = (450, 400)    # bottom-right corner of the static bounding box\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Draw the static bounding box on the frame\n",
    "    cv2.rectangle(frame, static_box_start, static_box_end, (0, 255, 0), 2)\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            # Scale up the face location\n",
    "            top, right, bottom, left = [v * 4 for v in face_location]\n",
    "\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "            # Check if the face is inside the static bounding box\n",
    "            if (left > static_box_start[0] and right < static_box_end[0] and \n",
    "                top > static_box_start[1] and bottom < static_box_end[1]):\n",
    "                \n",
    "                if name == \"Unknown\":\n",
    "                    # Capture the image and save it for a new person\n",
    "                    newperson(frame)  # Custom function to handle new person\n",
    "                    append_face_encodings_to_csv(image_folder='testimage', csv_filename='facedetails.csv')\n",
    "                    known_face_encodings, known_face_names = load_face_encodings_from_csv('facedetails.csv')\n",
    "\n",
    "                # Greet the detected person if not already greeted\n",
    "                if name != \"Unknown\" and name not in greeted_names:\n",
    "                    greet_person(name)\n",
    "                    greeted_names.add(name)  # Add name to the set of greeted names\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Optionally, draw the person's name on the screen\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartmirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
